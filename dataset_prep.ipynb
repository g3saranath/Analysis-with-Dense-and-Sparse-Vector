{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Financial Stock Price Dataset: Daily or intraday data for various stocks, which can be obtained from financial databases like Yahoo Finance or Alpha Vantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2023-01-03  243.080002  245.750000  237.399994  239.580002  236.183502   \n",
      "2023-01-04  232.279999  232.869995  225.960007  229.100006  225.852097   \n",
      "2023-01-05  227.199997  227.550003  221.759995  222.309998  219.158356   \n",
      "2023-01-06  223.000000  225.759995  219.350006  224.929993  221.741211   \n",
      "2023-01-09  226.449997  231.240005  226.410004  227.119995  223.900162   \n",
      "\n",
      "              Volume    Company  \n",
      "Date                             \n",
      "2023-01-03  25740000  Microsoft  \n",
      "2023-01-04  50623400  Microsoft  \n",
      "2023-01-05  39585600  Microsoft  \n",
      "2023-01-06  43613600  Microsoft  \n",
      "2023-01-09  27369800  Microsoft  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Fetching historical stock prices from Yahoo Finance\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the stock ticker and time period\n",
    "ticker = 'AAPL'\n",
    "data = yf.download(ticker, start='2023-01-01', end='2024-05-01')\n",
    "data[\"Company\"] = \"Apple\"\n",
    "\n",
    "ticker = 'MSFT'\n",
    "data2 = yf.download(ticker, start='2023-01-01', end='2024-05-01')\n",
    "data2[\"Company\"] = \"Microsoft\"\n",
    "\n",
    "print(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/apple_stock.csv\")\n",
    "data2.to_csv(\"data/msft_stock.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>3.330000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>173.830030</td>\n",
       "      <td>175.402523</td>\n",
       "      <td>172.508378</td>\n",
       "      <td>174.054655</td>\n",
       "      <td>173.113882</td>\n",
       "      <td>5.955436e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.985741</td>\n",
       "      <td>15.743105</td>\n",
       "      <td>15.953854</td>\n",
       "      <td>15.806214</td>\n",
       "      <td>15.920892</td>\n",
       "      <td>1.797261e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>126.010002</td>\n",
       "      <td>127.769997</td>\n",
       "      <td>124.169998</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>123.855095</td>\n",
       "      <td>2.404830e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>166.539993</td>\n",
       "      <td>168.559998</td>\n",
       "      <td>165.649994</td>\n",
       "      <td>167.039993</td>\n",
       "      <td>166.321625</td>\n",
       "      <td>4.772020e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>175.720001</td>\n",
       "      <td>177.580002</td>\n",
       "      <td>174.050003</td>\n",
       "      <td>175.839996</td>\n",
       "      <td>174.944794</td>\n",
       "      <td>5.494580e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>185.889999</td>\n",
       "      <td>187.330002</td>\n",
       "      <td>184.270004</td>\n",
       "      <td>186.009995</td>\n",
       "      <td>185.217163</td>\n",
       "      <td>6.613340e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.020004</td>\n",
       "      <td>199.619995</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>198.110001</td>\n",
       "      <td>197.361084</td>\n",
       "      <td>1.543573e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open        High         Low       Close   Adj Close  \\\n",
       "count  333.000000  333.000000  333.000000  333.000000  333.000000   \n",
       "mean   173.830030  175.402523  172.508378  174.054655  173.113882   \n",
       "std     15.985741   15.743105   15.953854   15.806214   15.920892   \n",
       "min    126.010002  127.769997  124.169998  125.019997  123.855095   \n",
       "25%    166.539993  168.559998  165.649994  167.039993  166.321625   \n",
       "50%    175.720001  177.580002  174.050003  175.839996  174.944794   \n",
       "75%    185.889999  187.330002  184.270004  186.009995  185.217163   \n",
       "max    198.020004  199.619995  197.000000  198.110001  197.361084   \n",
       "\n",
       "             Volume  \n",
       "count  3.330000e+02  \n",
       "mean   5.955436e+07  \n",
       "std    1.797261e+07  \n",
       "min    2.404830e+07  \n",
       "25%    4.772020e+07  \n",
       "50%    5.494580e+07  \n",
       "75%    6.613340e+07  \n",
       "max    1.543573e+08  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Stock Prices:\n",
    "\n",
    "- Handle missing values by forward-filling or removing them.\n",
    "- Normalize prices or returns to bring them into a common scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Returns  Normalized_Returns\n",
      "Date                                    \n",
      "2023-01-03  0.000000           -0.080077\n",
      "2023-01-04  0.010314            0.720935\n",
      "2023-01-05 -0.010605           -0.903638\n",
      "2023-01-06  0.036794            2.777383\n",
      "2023-01-09  0.004089            0.237454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/1kl1q_0d63q22lq9m6yqrwvh0000gn/T/ipykernel_61527/2474532667.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward-fill missing values\n"
     ]
    }
   ],
   "source": [
    "# Example: Cleaning and normalizing stock price data\n",
    "data.fillna(method='ffill', inplace=True)  # Forward-fill missing values\n",
    "data['Returns'] = data['Adj Close'].pct_change().fillna(0)  # Calculate daily returns\n",
    "data['Normalized_Returns'] = (data['Returns'] - data['Returns'].mean()) / data['Returns'].std()\n",
    "\n",
    "print(data[['Returns', 'Normalized_Returns']].head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Financial News Articles: News articles related to the stock market, which can be sourced from news aggregators like Google News, or specific financial news providers like Bloomberg or Reuters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "                                               title       date  \\\n",
      "0  Apple announces new MacBook Air laptops with i... 2024-03-04   \n",
      "1  Here's what Meta CEO Mark Zuckerberg has to sa... 2024-02-14   \n",
      "2  Apple's Vision Pro virtual reality headset lau... 2024-02-02   \n",
      "3  Apple Vision Pro review: This is the future of... 2024-01-30   \n",
      "4  Apple $3,499 Vision Pro headset now available ... 2024-01-19   \n",
      "\n",
      "                                                text  \\\n",
      "0  Apple on Monday announced new versions of its ...   \n",
      "1  Meta CEO Mark Zuckerberg demonstrates an Oculu...   \n",
      "2  The first customer walks out of the Apple Stor...   \n",
      "3  In this article AAPL Follow your favorite stoc...   \n",
      "4  Preorders for Apple 's $3,499 Vision Pro heads...   \n",
      "\n",
      "                             source  \n",
      "0  https://www.cnbc.com/technology/  \n",
      "1  https://www.cnbc.com/technology/  \n",
      "2  https://www.cnbc.com/technology/  \n",
      "3  https://www.cnbc.com/technology/  \n",
      "4  https://www.cnbc.com/technology/  \n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define news sources to scrape\n",
    "news_sources = [\n",
    "    \"https://www.reuters.com/technology/\",\n",
    "    \"https://www.cnbc.com/technology/\",\n",
    "    \"https://www.bloomberg.com/technology\"\n",
    "    \"https://www.forbes.com/sites/technology/\"\n",
    "    \"https://www.businesstoday.in/latest/economy/\"\n",
    "]\n",
    "\n",
    "# Keywords to filter articles\n",
    "keywords = [\"Apple\", \"iPhone\",\"Apple Vision Pro\",\"AAPL\",\"MacBook\", \"iPad\",]\n",
    "\n",
    "# Date range for filtering\n",
    "start_date = datetime(2022, 8, 1)\n",
    "end_date = datetime(2024, 5, 1)\n",
    "\n",
    "# Function to collect articles\n",
    "def collect_articles(news_sources, keywords, start_date, end_date):\n",
    "    articles = []\n",
    "    \n",
    "    for source in news_sources:\n",
    "        paper = newspaper.build(source, memoize_articles=False)\n",
    "        \n",
    "        for article in paper.articles:\n",
    "            try:\n",
    "                article.download()\n",
    "                article.parse()\n",
    "\n",
    "                # Check if the article's publication date is within the desired range\n",
    "                if article.publish_date and start_date <= article.publish_date <= end_date:\n",
    "                    # Check if the article contains any of the keywords\n",
    "                    if any(keyword in article.text for keyword in keywords):\n",
    "                        articles.append({\n",
    "                            \"title\": article.title,\n",
    "                            \"date\": article.publish_date,\n",
    "                            \"text\": article.text,\n",
    "                            \"source\": source\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download article: {e}\")\n",
    "    \n",
    "    return articles\n",
    "\n",
    "# Collect articles\n",
    "articles = collect_articles(news_sources, keywords, start_date, end_date)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(articles)\n",
    "df.dropna(subset=['date'], inplace=True)  # Drop articles without a publish date\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "#df.to_csv('apple_microsoft_financial_news.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple announces new MacBook Air laptops with i...</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>Apple on Monday announced new versions of its ...</td>\n",
       "      <td>https://www.cnbc.com/technology/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here's what Meta CEO Mark Zuckerberg has to sa...</td>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Meta CEO Mark Zuckerberg demonstrates an Oculu...</td>\n",
       "      <td>https://www.cnbc.com/technology/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple's Vision Pro virtual reality headset lau...</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>The first customer walks out of the Apple Stor...</td>\n",
       "      <td>https://www.cnbc.com/technology/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple Vision Pro review: This is the future of...</td>\n",
       "      <td>2024-01-30</td>\n",
       "      <td>In this article AAPL Follow your favorite stoc...</td>\n",
       "      <td>https://www.cnbc.com/technology/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple $3,499 Vision Pro headset now available ...</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>Preorders for Apple 's $3,499 Vision Pro heads...</td>\n",
       "      <td>https://www.cnbc.com/technology/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       date  \\\n",
       "0  Apple announces new MacBook Air laptops with i... 2024-03-04   \n",
       "1  Here's what Meta CEO Mark Zuckerberg has to sa... 2024-02-14   \n",
       "2  Apple's Vision Pro virtual reality headset lau... 2024-02-02   \n",
       "3  Apple Vision Pro review: This is the future of... 2024-01-30   \n",
       "4  Apple $3,499 Vision Pro headset now available ... 2024-01-19   \n",
       "\n",
       "                                                text  \\\n",
       "0  Apple on Monday announced new versions of its ...   \n",
       "1  Meta CEO Mark Zuckerberg demonstrates an Oculu...   \n",
       "2  The first customer walks out of the Apple Stor...   \n",
       "3  In this article AAPL Follow your favorite stoc...   \n",
       "4  Preorders for Apple 's $3,499 Vision Pro heads...   \n",
       "\n",
       "                             source  \n",
       "0  https://www.cnbc.com/technology/  \n",
       "1  https://www.cnbc.com/technology/  \n",
       "2  https://www.cnbc.com/technology/  \n",
       "3  https://www.cnbc.com/technology/  \n",
       "4  https://www.cnbc.com/technology/  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/apple_financial_news.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n",
      "Failed to download article: can't compare offset-naive and offset-aware datetimes\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define news sources to scrape\n",
    "news_sources = [\n",
    "    \"https://www.reuters.com/technology/\",\n",
    "    \"https://www.cnbc.com/technology/\",\n",
    "    \"https://www.bloomberg.com/technology\"\n",
    "    \"https://www.forbes.com/sites/technology/\"\n",
    "    \"https://www.businesstoday.in/latest/economy/\"\n",
    "]\n",
    "\n",
    "# Keywords to filter articles\n",
    "keywords = [\"Microsoft\"]\n",
    "\n",
    "# Date range for filtering\n",
    "start_date = datetime(2022, 8, 1)\n",
    "end_date = datetime(2024, 5, 1)\n",
    "\n",
    "# Function to collect articles\n",
    "def collect_articles(news_sources, keywords, start_date, end_date):\n",
    "    articles = []\n",
    "    \n",
    "    for source in news_sources:\n",
    "        paper = newspaper.build(source, memoize_articles=False)\n",
    "        \n",
    "        for article in paper.articles:\n",
    "            try:\n",
    "                article.download()\n",
    "                article.parse()\n",
    "\n",
    "                # Check if the article's publication date is within the desired range\n",
    "                if article.publish_date and start_date <= article.publish_date <= end_date:\n",
    "                    # Check if the article contains any of the keywords\n",
    "                    if any(keyword in article.text for keyword in keywords):\n",
    "                        articles.append({\n",
    "                            \"title\": article.title,\n",
    "                            \"date\": article.publish_date,\n",
    "                            \"text\": article.text,\n",
    "                            \"source\": source\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download article: {e}\")\n",
    "    \n",
    "    return articles\n",
    "\n",
    "# Collect articles\n",
    "articles = collect_articles(news_sources, keywords, start_date, end_date)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df_msft = pd.DataFrame(articles)\n",
    "df_msft.dropna(subset=['date'], inplace=True)  # Drop articles without a publish date\n",
    "\n",
    "print(df_msft.head())\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "df_msft.to_csv('data/microsoft_financial_news.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e646c1d0f36d352194803eb1b3bd6a8438ff42a362f7da11dd92f9220eb2998e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
